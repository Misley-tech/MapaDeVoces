{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import math\n",
    "\n",
    "def PitchPorPersona(y,sr):\n",
    "    f0, voiced_flag, voiced_probs=librosa.pyin(\n",
    "        y,\n",
    "        fmin=librosa.note_to_hz('C2'),\n",
    "        fmax=librosa.note_to_hz('C7'),\n",
    "        sr=sr)\n",
    "    f0 = [x for x in f0 if not isinstance(x, float) or not math.isnan(x)]\n",
    "    f0 = [i for i in f0 if i != 0]\n",
    "    return f0\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def Promediador(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "import pyloudnorm as pyln\n",
    "import librosa \n",
    "\n",
    "def LoudnessPorPersona(y,sr):\n",
    "    meter = pyln.Meter(sr)\n",
    "    loudness = meter.integrated_loudness(y)\n",
    "    return loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "def WordSplitter(chunk_name,path,min_silence_len,silence_thresh,chunk_storage_directory):\n",
    "    sound_file = AudioSegment.from_wav(path)\n",
    "    audio_chunks = split_on_silence(sound_file,min_silence_len,silence_thresh)\n",
    "    for i, chunk in enumerate(audio_chunks):\n",
    "        out_file = f\"{chunk_storage_directory}/chunk{i}_de_{chunk_name}.wav\"\n",
    "        print(\"exporting\", out_file)\n",
    "        chunk.export(out_file, format=\"wav\")\n",
    "\n",
    "chunk_name = 'HolaComoEstasPitched2'\n",
    "path = 'C:/Users/Asus/OneDrive/Escritorio/MapaDeVoces/Prototipos/Prototipo2/Audios/HolaComoEstasPitched51.wav'\n",
    "chunk_storage_directory = 'C:/Users/Asus/OneDrive/Escritorio/MapaDeVoces/Prototipos/Prototipo3/AudiosPrototipo3'\n",
    "min_silence_len = 11 # must be silent for at least half a second\n",
    "silence_thresh=-25 # consider it silent if quieter than -16 dBFS    \n",
    "WordSplitter(chunk_name,path,min_silence_len,silence_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def CalculadoraParametrosAcusticos(path_carpeta, nombre, cant_audios, extension, cant_basesdedatos):\n",
    "    df = pd.DataFrame(columns=['Pitch', 'Loudness','Tipo'])\n",
    "    for j in range(cant_basesdedatos):\n",
    "        for i in range(cant_audios):\n",
    "            path = f'{path_carpeta}/{nombre[j]}{i}.{extension[j]}'    \n",
    "            y,sr = librosa.load(path)\n",
    "            p=Promediador(PitchPorPersona(y,sr))\n",
    "            l=Promediador(LoudnessPorPersona(y,sr))\n",
    "            if j==0:\n",
    "                variable_tipo = 'Normal' \n",
    "            elif j==1:\n",
    "                variable_tipo = 'Pitched'\n",
    "            df = df.append({'Pitch':p, 'Loudness':l,'Tipo':variable_tipo},ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_carpeta = 'C:/Users/Asus/OneDrive/Escritorio/MapaDeVoces/Prototipos/Prototipo2/Audios'\n",
    "nombre = ['HolaComoEstas','HolaComoEstasPitched']\n",
    "extension = ['opus','wav']\n",
    "cant_audios = 56\n",
    "cant_basesdedatos = 2\n",
    "\n",
    "BaseDeDatos=CalculadoraParametrosAcusticos(path_carpeta,nombre,cant_audios,extension,cant_basesdedatos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "pitch = BaseDeDatos['Pitch']\n",
    "pitch = np.asarray(pitch)\n",
    "pitch = pitch.reshape(-1, 1)\n",
    "scaled_pitch = StandardScaler().fit_transform(pitch) # estandariza los valores\n",
    "\n",
    "embedding = reducer.fit_transform(pitch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(\n",
    "    embedding, x=0, y=1,\n",
    "    color=BaseDeDatos.Tipo, labels={'color': 'Tipo'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=True,\n",
    "    width=800,\n",
    "    height=500,\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
